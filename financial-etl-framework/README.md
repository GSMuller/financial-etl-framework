# Financial ETL Framework

[![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13+-336791.svg)](https://www.postgresql.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License: Private](https://img.shields.io/badge/License-Private-red.svg)]()

> Robust ETL framework for financial Data Warehouse with PostgreSQL, focused on controllership and operational data analysis.

---

## ğŸ“‹ Table of Contents

- [About The Project](#-about-the-project)
- [Architecture](#-architecture)
- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Testing](#-testing)
- [Contributing](#-contributing)

---

## ğŸ¯ About The Project

The **Financial ETL Framework** is a complete solution for consolidating financial and operational data into a PostgreSQL Data Warehouse. Designed to support controllership processes, the framework integrates data from multiple sources (BigQuery, spreadsheets, internal systems) applying transformations, validations, and business rules.

### Problem Solved

Centralize and standardize fragmented financial data across different systems, ensuring:
- âœ… Data integrity and traceability
- âœ… Automated daily ingestions
- âœ… Consistent business rule application
- âœ… Support for management reports and analysis

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA SOURCES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   BigQuery      â”‚  AppSheet/       â”‚   Internal             â”‚
â”‚  (Operational)  â”‚  Google Sheets   â”‚   Systems              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                     â”‚
         â–¼                 â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAW LAYER (Bronze)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  raw_bq      â”‚  â”‚raw_cadastro  â”‚  â”‚  raw_manual  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ ETL Pipeline
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STAGING LAYER (Silver)                     â”‚
â”‚        Cleaning â€¢ Normalization â€¢ Standardization            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  stg_billing   â”‚  stg_registration  â”‚  stg_bonus    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Business Rules
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MART LAYER (Gold)                          â”‚
â”‚         Analytical Views â€¢ Aggregations â€¢ KPIs               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  mart_controlling  â”‚  mart_incentives  â”‚  metrics    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  BI Dashboards  â”‚
                    â”‚    Reports      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Pipeline

1. **Extraction**: Data collection from BigQuery, spreadsheets, and systems
2. **Loading (Raw)**: Raw storage without transformations
3. **Staging**: Cleaning, validation, and normalization
4. **Transformation**: Business rules application (triggers, functions)
5. **Mart**: Analytical layer optimized for consumption

---

## âœ¨ Features

### Core Features
- ğŸ”„ **Automated ETL**: Complete Extract-Transform-Load pipeline
- ğŸ—ƒï¸ **Layered Architecture**: Raw â†’ Staging â†’ Mart (Medallion)
- ğŸ” **Security**: Credentials via environment variables (.env)
- ğŸ“Š **BigQuery Integration**: Daily operational data ingestion
- ğŸ§ª **Automated Testing**: Coverage with pytest
- ğŸ“ **Complete Logging**: Tracking of all operations

### Specific Functionalities
- ğŸ’° Automatic BYD bonus calculation
- ğŸ”„ Trigger system for data propagation
- ğŸ“ˆ Materialized views for performance
- ğŸ¯ Referential integrity validation
- ğŸ“… Data versioning control

---

## ğŸš€ Installation

### Prerequisites

- Python 3.9 or higher
- PostgreSQL 13 or higher
- Git

### Steps

1. **Clone the repository**
```bash
git clone https://github.com/GSMuller/financial-etl-framework.git
cd financial-etl-framework
```

2. **Create a virtual environment**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies**
```bash
# Basic installation
pip install -e .

# With development tools
pip install -e ".[dev]"

# With notebook support
pip install -e ".[notebooks]"

# Complete installation
pip install -e ".[dev,notebooks,excel]"
```

4. **Configure environment variables**

Create a `.env` file in the project root:
```env
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=financial_dw
DB_USER=your_username
DB_PASSWORD=your_password

# BigQuery (optional)
GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
BQ_PROJECT_ID=your-project
BQ_DATASET=your_dataset
```

5. **Run database migrations**
```bash
# Create schemas
psql -h localhost -U your_user -d financial_dw -f schemas/byd/tables/create/create_all.sql

# Create triggers
psql -h localhost -U your_user -d financial_dw -f schemas/byd/triggers/install_triggers.sql
```

---

## ğŸ’» Usage

### Basic Example

```python
from financial_etl import get_connection, db_connection

# Using context manager (recommended)
with db_connection() as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM mart_controlling.bonus_summary")
    results = cursor.fetchall()
    
    for row in results:
        print(row)
```

### Run Complete ETL

```python
from financial_etl.pipelines import run_daily_etl

# Execute the complete pipeline
result = run_daily_etl(date='2026-01-08')
print(f"Pipeline executed: {result['status']}")
print(f"Records processed: {result['records_processed']}")
```

### Transaction Rollback

```bash
python src/financial_etl/rollback.py
```

### Run Tests

```bash
# All tests
pytest

# With coverage report
pytest --cov=financial_etl --cov-report=html

# Specific test
pytest tests/test_conn.py -v
```

---

## ğŸ“ Project Structure

```
financial-etl-framework/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ financial_etl/          # Main source code
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # Configuration and logging
â”‚       â”œâ”€â”€ conn.py             # Connection management
â”‚       â””â”€â”€ rollback.py         # Rollback utility
â”œâ”€â”€ tests/                      # Automated tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_conn.py
â”‚   â””â”€â”€ test_rollback.py
â”œâ”€â”€ schemas/                    # SQL schemas
â”‚   â”œâ”€â”€ byd/
â”‚   â”‚   â”œâ”€â”€ tables/
â”‚   â”‚   â”‚   â”œâ”€â”€ create/        # Creation scripts
â”‚   â”‚   â”‚   â”œâ”€â”€ alter/         # Schema alterations
â”‚   â”‚   â”‚   â”œâ”€â”€ insert/        # Insertion scripts
â”‚   â”‚   â”‚   â””â”€â”€ view&conults/  # Views and queries
â”‚   â”‚   â””â”€â”€ triggers/          # Triggers and PL/pgSQL functions
â”‚   â””â”€â”€ nd/
â”œâ”€â”€ Datasets/                   # Sample data (not versioned)
â”œâ”€â”€ controlling_postgreSQL/     # Legacy scripts
â”œâ”€â”€ docs/                       # Additional documentation
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/              # CI/CD GitHub Actions
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ requirements.txt            # Dependencies (legacy)
â”œâ”€â”€ pytest.ini                  # Pytest configuration
â”œâ”€â”€ Dockerfile                  # Docker container
â”œâ”€â”€ .env.example                # Environment variables template
â”œâ”€â”€ CHANGELOG.md                # Change history
â””â”€â”€ README.md                   # This file
```

---

## ğŸ§ª Testing

The project uses **pytest** with code coverage:

```bash
# Run all tests
pytest

# With verbose output
pytest -v

# Generate HTML coverage report
pytest --cov=financial_etl --cov-report=html

# Open report in browser
# File will be at htmlcov/index.html
```

### Current Coverage

- `config.py`: 95%
- `conn.py`: 98%
- `rollback.py`: 92%

---

## ğŸ³ Docker

### Build Image

```bash
docker build -t financial-etl-framework .
```

### Run Container

```bash
docker run -d \
  --name financial-etl \
  -e DB_HOST=host.docker.internal \
  -e DB_NAME=financial_dw \
  -e DB_USER=username \
  -e DB_PASSWORD=password \
  financial-etl-framework
```

---

## ğŸ“Š Project Metrics

- **Language**: Python 58.1%
- **SQL**: 5.7%
- **Jupyter Notebooks**: 36.2%
- **Test Coverage**: ~95%
- **Lines of Code**: ~5,000+

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Code Style

The project uses:
- **black** for code formatting
- **isort** for import organization
- **flake8** for linting
- **mypy** for type checking

```bash
# Format code
black src/ tests/

# Organize imports
isort src/ tests/

# Quality check
flake8 src/ tests/
```

---

## ğŸ“„ License

Private project - All rights reserved.

---

## ğŸ‘¤ Author

**Giovanni Muller**

- GitHub: [@GSMuller](https://github.com/GSMuller)
- LinkedIn: [Giovanni Muller](https://www.linkedin.com/in/giovanni-muller)

---

## ğŸ“ Changelog

See [CHANGELOG.md](CHANGELOG.md) for complete version history.

---

## ğŸ™ Acknowledgments

- Servopa Controllership Team
- PostgreSQL Community
- Open-source contributors

---

**â­ If this project was helpful, please consider giving it a star!**
